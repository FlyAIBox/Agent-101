这张图片解释了软件开发从传统模式到基于大型语言模型（LLM）的现代模式的演变，将其分为三个阶段：**Software 1.0**、**Software 2.0** 和 **Software 3.0**。

### Software 1.0

* **核心**：`computer code` (计算机代码)。
* **描述**：这是传统的软件开发模式。开发者使用编程语言（如 Python, C++, Java）编写明确的、手动的指令，这些指令经过编译或解释后成为可执行的程序。
* **流程**：`computer code` → `programs` → `computer`。开发者编写代码，代码被执行，计算机按照代码中的精确指令完成任务。这个阶段的软件是完全由人编写的、可读的、可解释的代码。

### Software 2.0

* **核心**：`weights` (权重)。
* **描述**：这是机器学习和深度学习的时代。开发者不再手动编写所有指令，而是设计一个神经网络架构，并用大量数据进行训练。训练的结果就是模型中的“权重”，这些权重包含了从数据中学习到的模式和规则。
* **流程**：`weights` → `programs` → `neural net`。虽然最终运行的是程序，但其核心功能（如图像识别、语音识别）是由这些学习到的权重决定的。这些“程序”不再是人类可读的代码，而是一系列数值，其行为是由训练数据间接塑造的。

### Software 3.0

* **核心**：`prompts` (提示)。
* **描述**：这是基于大型语言模型（LLM）的最新软件范式。开发者不再需要关心编写代码或训练模型权重，而是通过自然语言向一个预训练好的 LLM 提供“提示”或指令，让 LLM 根据提示生成响应或完成任务。
* **流程**：`prompts` → `programs` → `LLM`。这里的“程序”是 LLM 自身，它已经包含了巨大的知识和能力。开发者只需要通过精心的提示（Prompts）来“编程”或引导 LLM 的行为。这种方式的门槛更低，更灵活，使得非程序员也可以“创建”复杂的应用。

### 总结

这张图形象地展示了软件核心的转变：
* 从人类直接编写的**代码**（Software 1.0）。
* 到人类通过数据训练出来的**权重**（Software 2.0）。
* 再到人类通过自然语言提供的**提示**（Software 3.0）。

这个演变过程反映了软件开发抽象层次的不断提升，让软件的创建和控制变得越来越简单和通用。

----
好的，这张图提供了更详细的对比和数学公式，可以更深入地解释软件范式的演变。

这张图完美地将软件演进的三个阶段与核心概念、执行方式和底层原理联系起来。

### Software 1.0 (确定性规则)

* **核心**: **计算机代码** (`computer code`)
* **描述**: 这是我们最熟悉的编程范式。
    * 开发者编写**显式的、人类可读的指令**。
    * 这些代码经过**编译/解释**，生成可执行的程序。
    * `Computer` 严格按照这些指令执行，每一步都是可预测、可解释的。
* **数学/原理**: `y = f(code(x))`。这意味着输出 `y` 是通过一个确定的函数 `f` 对输入 `x` 和代码 `code` 进行操作得到的。其复杂度通常用大 O 符号表示，例如 `O(n log n)`。这是**确定性规则（Deterministic Rules）** 的世界，只要输入和代码不变，输出永远相同。

### Software 2.0 (数据驱动参数)

* **核心**: **权重** (`weights`)
* **描述**: 这是机器学习范式。
    * 开发者不再编写指令，而是通过数据训练来获得**从数据中学习到的参数**，即 `weights`。
    * 这些权重被用于**推理、服务**和**模型调用**，形成了“程序”。
    * 这些程序在 `Neural Net` 上运行，能够执行如图像分类、自然语言处理等任务。
* **数学/原理**: 训练目标是**最小化损失函数** `L(f_w(x), y)`，其中 `f_w` 是由权重 `w` 参数化的函数。通过参数更新公式 `w <- w - η∇L` (梯度下降)，模型逐步调整权重，以减小预测与真实值之间的差距。这代表了**数据驱动参数（Data-Driven Parameters）** 的范式，模型的行为是由数据决定的。

### Software 3.0 (自然语言编程)

* **核心**: **提示词** (`prompts`)
* **描述**: 这是基于大型语言模型（LLM）的最新范式。
    * 开发者不再需要训练模型或编写复杂代码。他们用**自然语言、系统指令**或**工具描述**来编写**提示词**。
    * 这些提示词通过**编程、代理、函数调用**等方式，作为输入发送给 LLM。
    * `LLM` 是一个巨大的、预训练好的通用程序，它接收提示词并生成响应。
* **数学/原理**:
    * **条件概率**: `p(t | c, prompt)`。这表示给定上下文 `c` 和提示词 `prompt`，生成下一个词元 `t` 的概率。
    * **softmax**: `softmax(z_i) = e^(z_i/τ) / Σ_j e^(z_j/τ)`。LLM 使用 softmax 函数将输出的对数几率（logits）转换为概率分布，以决定生成哪个词。
    * **困惑度（Perplexity）**: `PP = exp(-1/N Σ log p(w_i))`。这是一种衡量模型预测能力好坏的指标，值越小越好。
    * 这是**自然语言编程（Natural-Language Programming）** 的范式，其行为是通过自然语言而不是传统代码来控制的。

### 综合总结

这张图将软件演进的抽象层次清晰地呈现出来：

* **Software 1.0**: 直接编写可读、可解释的指令，控制**计算机**。
* **Software 2.0**: 通过数据训练不可读的权重，控制**神经网络**。
* **Software 3.0**: 通过自然语言编写提示词，控制**大型语言模型**。

这个过程本质上是将**编程的责任**从人类程序员身上，逐步转移到由数据和计算力驱动的智能系统上，极大地降低了编程的门槛，并开启了通用人工智能应用的新时代。